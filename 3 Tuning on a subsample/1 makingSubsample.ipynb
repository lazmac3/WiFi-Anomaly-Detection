{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a30673-c306-426b-b29c-c7d4b546efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d5508-2fd8-448d-a8e7-2d4cae8f14f3",
   "metadata": {},
   "source": [
    "The next stage of the project is looking at the algorithims, and working with a reduced set of dimensions, looking at imporving our random forest and trying other algorithims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca80d56-7e03-42be-ae46-f2727a41eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths=['Data/parquet/1.Deauth',\n",
    "       'Data/parquet/2.Disas',\n",
    "       'Data/parquet/3.(Re)Assoc',\n",
    "       'Data/parquet/4.Rogue_AP',\n",
    "       'Data/parquet/5.Krack',\n",
    "       'Data/parquet/6.Kr00k',\n",
    "       'Data/parquet/7.SSH',\n",
    "       'Data/parquet/8.Botnet',\n",
    "       'Data/parquet/9.Malware',\n",
    "       'Data/parquet/10.SQL_Injection',\n",
    "       'Data/parquet/11.SSDP',\n",
    "       'Data/parquet/12.Evil_Twin',\n",
    "       'Data/parquet/13.Website_spoofing'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568f24af-506e-49ee-b2d0-463093f550b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e74d5e-ef53-4f92-b285-3919dc3bc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"WiFi\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814ba7fe-44ad-49a1-b7c3-f31d5959582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.parquet(*paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2860e76c-29aa-4c52-8837-f89ce4c129ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|     StringLabel|   count|\n",
      "+----------------+--------+\n",
      "|          Normal|30387099|\n",
      "|           Krack|   49990|\n",
      "|          Botnet|   56891|\n",
      "|   SQL_Injection|    2629|\n",
      "|       (Re)Assoc|    5502|\n",
      "|             SSH|   11882|\n",
      "|       Evil_Twin|  104827|\n",
      "|Website_spoofing|  405121|\n",
      "|              NA|      34|\n",
      "|         Malware|  131611|\n",
      "|          Deauth|   38942|\n",
      "|         RogueAP|    1310|\n",
      "|            SSDP| 5499851|\n",
      "|           Kr00k|  191803|\n",
      "|           Disas|   75131|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36962623"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('StringLabel').count().show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709200e-d7cb-4250-955a-de345d7f8d0d",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/azure/databricks/_static/notebooks/getting-started/get-started-with-mllib-dbr7.html as a guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ce436-e81e-414f-989f-b3794d400565",
   "metadata": {},
   "source": [
    "We want to use a stratified subsample, we need a small sample for the grid search, and a larger group to test and train on. This is to allow experimentation with results in a reasonable time. Once we have this infomation we can run on the full dataset either in the cloud or locally overnight. I found when working locally on my machine the higher entropy of using multiple attacks led to longer run times, with the tree bagging scores getting large and pushing the data out of memory and causing thrashing. I selected my sample wanting to get a sample of all the attacks but also bearing in mind the power of my computer which is a fairly powerful gaming laptop.  I aimed for about 3,000 of each attack, with a fraction at one significany figure,althou some of the attacks like SQL injection and Rogue AP have fewer attack packets than this. From test runs I found this allowed me to run a random forest locally in about 10-30 minutes which allows me to tune and test the algorithims.\n",
    "\n",
    "The official page of the random forest algorithim says \"Running on a data set with 50,000 cases and 100 variables, it produced 100 trees in 11 minutes on a 800Mhz machine\" This is about the run time I am looking for testing. My sample is a lot bigger but I will use fewer variables. \n",
    "\n",
    "For this we want the majority of packets to be normal. Some of the attacks (such as Website Spoofing and SSDP have a large percentage and large number of attack packets). I want my algorthims not to favour identifying these attacks, both because I do not have a reason to think they are more prevelant in the real world and because the management packet attacks are more useful to study. I mean this in the sense that the random forest is identifying the attack packet by packet type rather than the attacker by IP or MAC address.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.sampleBy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e50eb9-5008-41c9-af96-4b0d13ef00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|     StringLabel| count|\n",
      "+----------------+------+\n",
      "|          Normal|608992|\n",
      "|           Krack|  2514|\n",
      "|          Botnet|  2852|\n",
      "|   SQL_Injection|  2629|\n",
      "|       (Re)Assoc|  3413|\n",
      "|             SSH|  3534|\n",
      "|       Evil_Twin|  3105|\n",
      "|Website_spoofing|  2544|\n",
      "|         Malware|  2679|\n",
      "|          Deauth|  2220|\n",
      "|         RogueAP|  1310|\n",
      "|           Kr00k|  3790|\n",
      "|           Disas|  2977|\n",
      "|            SSDP|  2755|\n",
      "+----------------+------+\n",
      "\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    0|608992|\n",
      "|    1| 36322|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "645314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subSample = df.sampleBy(\"StringLabel\", fractions={\"Normal\": 0.02, \"Krack\": 0.05 ,\"Botnet\": 0.05 ,\"SQL_Injection\": 1,\"(Re)Assoc\": 0.6,\"SSH\": 0.3,\"Evil_Twin\": 0.03,\"Website_spoofing\": 0.006,\"Malware\": 0.02,\"Deauth\": 0.06,\"RogueAP\": 1,\"SSDP\": 0.0005,\"Kr00k\": 0.02,\"Disas\": 0.04, }, seed=0)\n",
    "subSample.groupBy('StringLabel').count().show()\n",
    "subSample.groupBy('label').count().show()\n",
    "subSample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00257abc-1ef3-49cc-9a6f-3553de5146e5",
   "metadata": {},
   "source": [
    "So here we are left with 645314 events and 94% Normal packets. \n",
    "\n",
    "We then want to write out our dataframe as a parquet file. This is so when we load the data we avoid data from the original dataframe staying in memory making basic calculations more time consuming. Spark can work with this whole dataset and much larger ones too, but the run time isn't necessarily appropriate for me as a part time masters student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afbd3f2-fb69-45f6-8e73-6b91b44d2f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writePath=\"Data/parquet/subSampleWholeDataSet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7d78d30-d402-441c-a508-d00ed44bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subSample.write.parquet(writePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543c0d9-c35d-45a0-ba31-2964ea945516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8f6b18b-9418-402b-8517-b49724976dd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e628dcb5-808e-406a-9d01-35aaaaa279dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96cfd2-da22-40ea-b5de-001477c13eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d98025-120b-463a-a00b-bbe535438b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fb6b6-caa4-4aff-9d29-06d32493d783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08fb80-cef9-4008-86aa-fd2168ab1d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b004f6-5bbb-49bc-bfaf-8e81ead93ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df185548-6ee8-4701-9498-76aadd213bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985d897-9508-4003-9175-515798bb965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135057f8-7198-4c96-bc8d-c6d3ed73dafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8ee3c-dded-449b-a2cd-d1683dd1d0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8724e5c-af62-44aa-a7f9-117cbe761d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae77ee8-f631-46e0-9859-7a88f04f7167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e64c3-5126-4427-bbf9-2526223443b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f0f18-cf7f-45c6-a348-eb507cfa5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a2f7a-d4a4-45a6-b4d4-512ad8027475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e939b6e-ee57-4c4d-812b-8465791c68fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c8631-153f-4b7b-bd22-57f9b16e1735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0555b-88c8-4279-ab3b-7d650be88a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba6b35-e9a4-42c2-8f9a-1865e6f60fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd878ccf-6de8-439e-933b-e4f877f1dab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
